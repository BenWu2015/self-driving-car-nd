{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load helper1.py\n",
    "import errno\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.misc\n",
    "from scipy.ndimage import rotate\n",
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some useful constants\n",
    "DRIVING_LOG_FILE = './data/driving_log.csv'\n",
    "IMG_PATH = './data/'\n",
    "STEERING_COEFFICIENT = 0.229\n",
    "\n",
    "\n",
    "def crop(image, top_percent, bottom_percent):\n",
    "    \"\"\"\n",
    "    Crops an image according to the given parameters\n",
    "\n",
    "    :param image: source image\n",
    "\n",
    "    :param top_percent:\n",
    "        The percentage of the original image will be cropped from the top of the image\n",
    "\n",
    "    :param bottom_percent:\n",
    "        The percentage of the original image will be cropped from the bottom of the image\n",
    "\n",
    "    :return:\n",
    "        The cropped image\n",
    "    \"\"\"\n",
    "    assert 0 <= top_percent < 0.5, 'top_percent should be between 0.0 and 0.5'\n",
    "    assert 0 <= bottom_percent < 0.5, 'top_percent should be between 0.0 and 0.5'\n",
    "\n",
    "    top = int(np.ceil(image.shape[0] * top_percent))\n",
    "    bottom = image.shape[0] - int(np.ceil(image.shape[0] * bottom_percent))\n",
    "\n",
    "    return image[top:bottom, :]\n",
    "\n",
    "\n",
    "def resize(image, new_dim):\n",
    "    \"\"\"\n",
    "    Resize a given image according the the new dimension\n",
    "\n",
    "    :param image:\n",
    "        Source image\n",
    "\n",
    "    :param new_dim:\n",
    "        A tuple which represents the resize dimension\n",
    "\n",
    "    :return:\n",
    "        Resize image\n",
    "    \"\"\"\n",
    "    return scipy.misc.imresize(image, new_dim)\n",
    "\n",
    "\n",
    "def random_flip(image, steering_angle, flipping_prob=0.5):\n",
    "    \"\"\"\n",
    "    Based on the outcome of an coin flip, the image will be flipped.\n",
    "    If flipping is applied, the steering angle will be negated.\n",
    "\n",
    "    :param image: Source image\n",
    "\n",
    "    :param steering_angle: Original steering angle\n",
    "\n",
    "    :return: Both flipped image and new steering angle\n",
    "    \"\"\"\n",
    "    head = bernoulli.rvs(flipping_prob)\n",
    "    if head:\n",
    "        return np.fliplr(image), -1 * steering_angle\n",
    "    else:\n",
    "        return image, steering_angle\n",
    "\n",
    "\n",
    "def random_gamma(image):\n",
    "    \"\"\"\n",
    "    Random gamma correction is used as an alternative method changing the brightness of\n",
    "    training images.\n",
    "    http://www.pyimagesearch.com/2015/10/05/opencv-gamma-correction/\n",
    "\n",
    "    :param image:\n",
    "        Source image\n",
    "\n",
    "    :return:\n",
    "        New image generated by applying gamma correction to the source image\n",
    "    \"\"\"\n",
    "    gamma = np.random.uniform(0.4, 1.5)\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "\n",
    "def random_shear(image, steering_angle, shear_range=200):\n",
    "    \"\"\"\n",
    "    Source: https://medium.com/@ksakmann/behavioral-cloning-make-a-car-drive-like-yourself-dc6021152713#.7k8vfppvk\n",
    "\n",
    "    :param image:\n",
    "        Source image on which the shear operation will be applied\n",
    "\n",
    "    :param steering_angle:\n",
    "        The steering angle of the image\n",
    "\n",
    "    :param shear_range:\n",
    "        Random shear between [-shear_range, shear_range + 1] will be applied\n",
    "\n",
    "    :return:\n",
    "        The image generated by applying random shear on the source image\n",
    "    \"\"\"\n",
    "    rows, cols, ch = image.shape\n",
    "    dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "    random_point = [cols / 2 + dx, rows / 2]\n",
    "    pts1 = np.float32([[0, rows], [cols, rows], [cols / 2, rows / 2]])\n",
    "    pts2 = np.float32([[0, rows], [cols, rows], random_point])\n",
    "    dsteering = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    image = cv2.warpAffine(image, M, (cols, rows), borderMode=1)\n",
    "    steering_angle += dsteering\n",
    "\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def random_rotation(image, steering_angle, rotation_amount=15):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image:\n",
    "    :param steering_angle:\n",
    "    :param rotation_amount:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    angle = np.random.uniform(-rotation_amount, rotation_amount + 1)\n",
    "    rad = (np.pi / 180.0) * angle\n",
    "    return rotate(image, angle, reshape=False), steering_angle + (-1) * rad\n",
    "\n",
    "\n",
    "def min_max(data, a=-0.5, b=0.5):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :param a:\n",
    "    :param b:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_max = np.max(data)\n",
    "    data_min = np.min(data)\n",
    "    return a + (b - a) * ((data - data_min) / (data_max - data_min))\n",
    "\n",
    "\n",
    "def generate_new_image(image, steering_angle, top_crop_percent=0.35, bottom_crop_percent=0.1,\n",
    "                       resize_dim=(64, 64), do_shear_prob=0.9):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image:\n",
    "    :param steering_angle:\n",
    "    :param top_crop_percent:\n",
    "    :param bottom_crop_percent:\n",
    "    :param resize_dim:\n",
    "    :param do_shear_prob:\n",
    "    :param shear_range:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    head = bernoulli.rvs(do_shear_prob)\n",
    "    if head == 1:\n",
    "        image, steering_angle = random_shear(image, steering_angle)\n",
    "\n",
    "    image = crop(image, top_crop_percent, bottom_crop_percent)\n",
    "\n",
    "    image, steering_angle = random_flip(image, steering_angle)\n",
    "\n",
    "    image = random_gamma(image)\n",
    "\n",
    "    image = resize(image, resize_dim)\n",
    "\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def get_next_image_files(batch_size=64):\n",
    "    \"\"\"\n",
    "    The simulator records three images (namely: left, center, and right) at a given time\n",
    "    However, when we are picking images for training we randomly (with equal probability)\n",
    "    one of these three images and its steering angle.\n",
    "\n",
    "    :param batch_size:\n",
    "        Size of the image batch\n",
    "\n",
    "    :return:\n",
    "        An list of selected (image files names, respective steering angles)\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(DRIVING_LOG_FILE)\n",
    "    num_of_img = len(data)\n",
    "    rnd_indices = np.random.randint(0, num_of_img, batch_size)\n",
    "\n",
    "    image_files_and_angles = []\n",
    "    for index in rnd_indices:\n",
    "        rnd_image = np.random.randint(0, 3)\n",
    "        if rnd_image == 0:\n",
    "            img = data.iloc[index]['left'].strip()\n",
    "            angle = data.iloc[index]['steering'] + STEERING_COEFFICIENT\n",
    "            image_files_and_angles.append((img, angle))\n",
    "\n",
    "        elif rnd_image == 1:\n",
    "            img = data.iloc[index]['center'].strip()\n",
    "            angle = data.iloc[index]['steering']\n",
    "            image_files_and_angles.append((img, angle))\n",
    "        else:\n",
    "            img = data.iloc[index]['right'].strip()\n",
    "            angle = data.iloc[index]['steering'] - STEERING_COEFFICIENT\n",
    "            image_files_and_angles.append((img, angle))\n",
    "\n",
    "    return image_files_and_angles\n",
    "\n",
    "\n",
    "def generate_next_batch(batch_size=64):\n",
    "    \"\"\"\n",
    "    This generator yields the next training batch\n",
    "\n",
    "    :param batch_size:\n",
    "        Number of training images in a single batch\n",
    "\n",
    "    :return:\n",
    "        A tuple of features and steering angles as two numpy arrays\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        images = get_next_image_files(batch_size)\n",
    "        for img_file, angle in images:\n",
    "            raw_image = plt.imread(IMG_PATH + img_file)\n",
    "            raw_angle = angle\n",
    "            new_image, new_angle = generate_new_image(raw_image, raw_angle)\n",
    "            X_batch.append(new_image)\n",
    "            y_batch.append(new_angle)\n",
    "\n",
    "        assert len(X_batch) == batch_size, 'len(X_batch) == batch_size should be True'\n",
    "\n",
    "        yield np.array(X_batch), np.array(y_batch)\n",
    "\n",
    "\n",
    "def save_model(model, model_name='model.json', weights_name='model.h5'):\n",
    "    \"\"\"\n",
    "    Save the model into the hard disk\n",
    "\n",
    "    :param model:\n",
    "        Keras model to be saved\n",
    "\n",
    "    :param model_name:\n",
    "        The name of the model file\n",
    "\n",
    "    :param weights_name:\n",
    "        The name of the weight file\n",
    "\n",
    "    :return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    silent_delete(model_name)\n",
    "    silent_delete(weights_name)\n",
    "\n",
    "    json_string = model.to_json()\n",
    "    with open(model_name, 'w') as outfile:\n",
    "        json.dump(json_string, outfile)\n",
    "\n",
    "    model.save_weights(weights_name)\n",
    "\n",
    "\n",
    "def silent_delete(file):\n",
    "    \"\"\"\n",
    "    This method delete the given file from the file system if it is available\n",
    "    Source: http://stackoverflow.com/questions/10840533/most-pythonic-way-to-delete-a-file-which-may-not-exist\n",
    "\n",
    "    :param file:\n",
    "        File to be deleted\n",
    "\n",
    "    :return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.remove(file)\n",
    "\n",
    "    except OSError as error:\n",
    "        if error.errno != errno.ENOENT:\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %load model1.py\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Flatten, Lambda, Activation, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 32, 24)    1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 32, 24)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 31, 31, 24)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 16, 16, 36)    21636       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 16, 16, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 15, 15, 36)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 8, 8, 48)      43248       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 8, 8, 48)      0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 7, 7, 48)      0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 7, 7, 64)      27712       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 7, 7, 64)      0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 6, 6, 64)      0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 6, 6, 64)      36928       maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 6, 6, 64)      0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 5, 5, 64)      0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1600)          0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1164)          1863564     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 1164)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           116500      activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 100)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 50)            5050        activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 50)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            510         activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 10)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             11          activation_9[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 2,116,983\n",
      "Trainable params: 2,116,983\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/8\n",
      "20032/20032 [==============================] - 1004s - loss: 0.1129 - val_loss: 0.0702\n",
      "Epoch 2/8\n",
      "20032/20032 [==============================] - 627s - loss: 0.0683 - val_loss: 0.0656\n",
      "Epoch 3/8\n",
      "20032/20032 [==============================] - 637s - loss: 0.0620 - val_loss: 0.0577\n",
      "Epoch 4/8\n",
      "20032/20032 [==============================] - 784s - loss: 0.0542 - val_loss: 0.0490\n",
      "Epoch 5/8\n",
      "20032/20032 [==============================] - 611s - loss: 0.0517 - val_loss: 0.0509\n",
      "Epoch 6/8\n",
      "20032/20032 [==============================] - 601s - loss: 0.0476 - val_loss: 0.0484\n",
      "Epoch 7/8\n",
      "20032/20032 [==============================] - 413s - loss: 0.0446 - val_loss: 0.0409\n",
      "Epoch 8/8\n",
      "20032/20032 [==============================] - 408s - loss: 0.0443 - val_loss: 0.0406\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "number_of_epochs = 8\n",
    "number_of_samples_per_epoch = 20032\n",
    "number_of_validation_samples = 6400\n",
    "learning_rate = 1e-4\n",
    "activation_relu = 'relu'\n",
    "\n",
    "# Our model is based on NVIDIA's \"End to End Learning for Self-Driving Cars\" paper\n",
    "# Source:  https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: x / 127.5 - 1.0, input_shape=(64, 64, 3)))\n",
    "\n",
    "# starts with five convolutional and maxpooling layers\n",
    "model.add(Convolution2D(24, 5, 5, border_mode='same', subsample=(2, 2)))\n",
    "model.add(Activation(activation_relu))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "model.add(Convolution2D(36, 5, 5, border_mode='same', subsample=(2, 2)))\n",
    "model.add(Activation(activation_relu))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "model.add(Convolution2D(48, 5, 5, border_mode='same', subsample=(2, 2)))\n",
    "model.add(Activation(activation_relu))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', subsample=(1, 1)))\n",
    "model.add(Activation(activation_relu))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', subsample=(1, 1)))\n",
    "model.add(Activation(activation_relu))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Next, five fully connected layers\n",
    "model.add(Dense(1164))\n",
    "model.add(Activation(activation_relu))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(activation_relu))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(activation_relu))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(activation_relu))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate), loss=\"mse\", )\n",
    "\n",
    "# create two generators for training and validation\n",
    "train_gen = generate_next_batch()\n",
    "validation_gen = generate_next_batch()\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              samples_per_epoch=number_of_samples_per_epoch,\n",
    "                              nb_epoch=number_of_epochs,\n",
    "                              validation_data=validation_gen,\n",
    "                              nb_val_samples=number_of_validation_samples,\n",
    "                              verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finally save our model and weights\n",
    "save_model(model)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
